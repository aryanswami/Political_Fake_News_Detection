# -*- coding: utf-8 -*-
"""Working_code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UegUJTbGwBAdvWo3x9UuKIBdL1nep-z3
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras.models import Model
from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, Dropout, Concatenate, Dot, Activation
from sklearn.model_selection import train_test_split
from keras.layers import Flatten, RepeatVector, Permute
from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical

# Load the dataset
df = pd.read_csv("/content/train_headlines_comb_up.csv")

# Split the dataset into training and testing sets
train_size = int(0.8 * len(df))
train_data = df[:train_size]
test_data = df[train_size:]

# Preprocess the text data
tokenizer = Tokenizer()
tokenizer.fit_on_texts(train_data["Headline"])
vocab_size = len(tokenizer.word_index) + 1

train_sequences = tokenizer.texts_to_sequences(train_data["Headline"])
train_padded = pad_sequences(train_sequences)

test_sequences = tokenizer.texts_to_sequences(test_data["Headline"])
test_padded = pad_sequences(test_sequences, maxlen=train_padded.shape[1])

# Define the BERT model for fact-checking
bert_inputs = Input(shape=(train_padded.shape[1],))
bert_embedding = Embedding(vocab_size, 100)(bert_inputs)
bert_lstm = Bidirectional(LSTM(64, return_sequences=True))(bert_embedding)
bert_dropout = Dropout(0.5)(bert_lstm)
bert_output = Dense(1, activation="sigmoid")(bert_dropout)
bert_model = Model(inputs=bert_inputs, outputs=bert_output)
bert_model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

# Train the BERT model
bert_model.fit(train_padded, train_data["Label"], validation_data=(test_padded, test_data["Label"]), epochs=10)

# Define the Bi-LSTM model with headline attention mechanism for bias detection
lstm_inputs = Input(shape=(train_padded.shape[1],))
lstm_embedding = Embedding(vocab_size, 100)(lstm_inputs)
lstm_lstm = Bidirectional(LSTM(64, return_sequences=True))(lstm_embedding)
lstm_dropout = Dropout(0.5)(lstm_lstm)
attention = Dense(1, activation="tanh")(lstm_dropout)
attention = Flatten()(attention)
attention = Activation("softmax")(attention)
attention = RepeatVector(128)(attention)
attention = Permute([2, 1])(attention)
lstm_output = Dot(axes=-1)([lstm_dropout, attention])
lstm_output = Dense(1, activation="sigmoid")(lstm_output)
lstm_model = Model(inputs=lstm_inputs, outputs=lstm_output)
lstm_model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

label_encoder = LabelEncoder()
train_labels = label_encoder.fit_transform(train_data["Political_Bias"])
test_labels = label_encoder.transform(test_data["Political_Bias"])

# Convert the labels to one-hot encoded vectors
num_classes = 22
train_labels = to_categorical(train_labels, num_classes)
test_labels = to_categorical(test_labels, num_classes)

# Train the Bi-LSTM model
lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
lstm_model.fit(train_padded, train_labels, validation_data=(test_padded, test_labels), epochs=10)

# Combine the models
combined_inputs = Input(shape=(train_padded.shape[1],))
bert_output = bert_model(combined_inputs)
lstm_output = lstm_model(combined_inputs)
combined_output = Concatenate()([bert_output, lstm_output])
combined_output = Dense(1, activation="sigmoid")(combined_output)
combined_model = Model(inputs=combined_inputs, outputs=combined_output)
combined_model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

# Train the combined model
combined_model.fit(train_padded, train_data["Label"], validation_data=(test_padded, test_data["Label"]), epochs=10)

# Evaluate the combined model
loss, accuracy = combined_model.evaluate(test_padded, test_data["Label"])
print("Combined Model - Loss: {:.4f}\n \t\t Accuracy: {:.4f}".format(loss, accuracy))

# Save the trained models
bert_model.save("bert_model.h5")
lstm_model.save("lstm_model.h5")
combined_model.save("combined_model.h5")

# Testing a new headline
headline = "Why is Amit Shah wanted?"
headline_sequence = tokenizer.texts_to_sequences([headline])
headline_padded = pad_sequences(headline_sequence, maxlen=train_padded.shape[1])

# Predict the label using the combined model
prediction = combined_model.predict(headline_padded)[0][0]

if prediction >= 0.5:
    print("The headline is predicted as REAL.")
else:
    print("The headline is predicted as FAKE.")